{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-22T07:01:24.267522Z",
     "start_time": "2025-04-22T07:01:23.695395Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:01:24.284050Z",
     "start_time": "2025-04-22T07:01:24.272004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuración\n",
    "PIXABAY_API_KEY = \"49861357-734e1eca2425b5e98b167e58f\"  # Reemplaza con tu clave de API de Pixabay\n",
    "CATEGORIES = [\"flowers\", \"mountains\", \"animals\", \"everyday objects\", \"urban environments\"]\n",
    "IMAGES_PER_CATEGORY = 1200  # Descargar más para tener margen\n",
    "FINAL_IMAGES_PER_CATEGORY = 1000  # Objetivo final\n",
    "TEMP_DIR = \"C:/Users/ctorr/OneDrive/Documentos/Arturo/Arturo HW ITESO/6to semestre/Modelos no lineales/GANs/data/raw\"  # Directorio temporal\n",
    "OUTPUT_DIR = \"C:/Users/ctorr/OneDrive/Documentos/Arturo/Arturo HW ITESO/6to semestre/Modelos no lineales/GANs/data/clean\"  # Directorio final\n",
    "LOG_FILE = \"dataset_preparation.log\"\n",
    "MIN_SIZE = (100, 100)  # Tamaño mínimo\n",
    "TARGET_SIZE = (256, 256)  # Tamaño objetivo\n",
    "SATURATION_THRESHOLD = 0.1  # Umbral de saturación\n",
    "PHASH_THRESHOLD = 5  # Umbral de distancia para pHash\n",
    "REQUESTS_PER_CYCLE = 100  # Máximo de solicitudes por ciclo\n",
    "PAUSE_SECONDS = 60  # Pausa entre ciclos"
   ],
   "id": "90bf5ec87ead7a2c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:01:24.474008Z",
     "start_time": "2025-04-22T07:01:24.459008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configurar logging\n",
    "logging.basicConfig(filename=LOG_FILE, level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ],
   "id": "46dc3bfe63a767d4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:01:24.505023Z",
     "start_time": "2025-04-22T07:01:24.490008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_images(category, temp_dir, max_images):\n",
    "    \"\"\"Descarga imágenes de Pixabay usando la API.\"\"\"\n",
    "    category_dir = os.path.join(temp_dir, category.replace(\" \", \"_\"))\n",
    "    Path(category_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Mostrar ruta de descarga\n",
    "    print(f\"\\nDescargando imágenes de '{category}' en: {os.path.abspath(category_dir)}\")\n",
    "    logging.info(f\"Iniciando descarga para '{category}' en: {os.path.abspath(category_dir)}\")\n",
    "    \n",
    "    count = 0\n",
    "    page = 1\n",
    "    requests_made = 0\n",
    "    \n",
    "    while count < max_images:\n",
    "        # Construir URL de la API\n",
    "        url = f\"https://pixabay.com/api/?key={PIXABAY_API_KEY}&q={category}&image_type=photo&per_page=100&page={page}\"\n",
    "        \n",
    "        try:\n",
    "            # Realizar solicitud\n",
    "            response = requests.get(url, timeout=10)\n",
    "            requests_made += 1\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                logging.warning(f\"Error en la solicitud para {category}, página {page}: {response.status_code}\")\n",
    "                break\n",
    "            \n",
    "            data = response.json()\n",
    "            hits = data.get('hits', [])\n",
    "            if not hits:\n",
    "                logging.info(f\"No más imágenes para {category} en la página {page}\")\n",
    "                break\n",
    "            \n",
    "            # Descargar imágenes\n",
    "            for i, hit in enumerate(tqdm(hits, desc=f\"Descargando {category}, página {page}\")):\n",
    "                if count >= max_images:\n",
    "                    break\n",
    "                img_url = hit['largeImageURL']\n",
    "                img_path = os.path.join(category_dir, f\"{category.replace(' ', '_')}_{count+1:04d}.jpg\")\n",
    "                try:\n",
    "                    img_response = requests.get(img_url, stream=True, timeout=10)\n",
    "                    if img_response.status_code == 200:\n",
    "                        with open(img_path, 'wb') as f:\n",
    "                            f.write(img_response.content)\n",
    "                        count += 1\n",
    "                    time.sleep(0.2)  # Pausa breve entre descargas\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error al descargar {img_url}: {str(e)}\")\n",
    "            \n",
    "            # Controlar límite de solicitudes\n",
    "            if requests_made >= REQUESTS_PER_CYCLE:\n",
    "                logging.info(f\"Límite de {REQUESTS_PER_CYCLE} solicitudes alcanzado. Pausando {PAUSE_SECONDS} segundos.\")\n",
    "                time.sleep(PAUSE_SECONDS)\n",
    "                requests_made = 0\n",
    "            \n",
    "            page += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error en la solicitud para {category}, página {page}: {str(e)}\")\n",
    "            break\n",
    "    \n",
    "    logging.info(f\"Descargadas {count} imágenes para {category}\")\n",
    "    return count"
   ],
   "id": "10800defb974942f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:01:24.536529Z",
     "start_time": "2025-04-22T07:01:24.523013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_image_corrupt(file_path):\n",
    "    \"\"\"Verifica si la imagen está corrupta.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        img.verify()\n",
    "        img = Image.open(file_path)\n",
    "        img.load()\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Imagen corrupta: {file_path}, Error: {str(e)}\")\n",
    "        return True\n",
    "\n",
    "def is_low_resolution(file_path):\n",
    "    \"\"\"Verifica si la imagen tiene resolución muy baja.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        width, height = img.size\n",
    "        if width < MIN_SIZE[0] or height < MIN_SIZE[1]:\n",
    "            logging.info(f\"Imagen de baja resolución descartada: {file_path}, Tamaño: {width}x{height}\")\n",
    "            return True\n",
    "        return False\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def is_monochromatic(file_path):\n",
    "    \"\"\"Verifica si la imagen es casi monocromática.\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(file_path)\n",
    "        if img is None:\n",
    "            return True\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        saturation = hsv[:, :, 1].mean() / 255.0\n",
    "        if saturation < SATURATION_THRESHOLD:\n",
    "            logging.info(f\"Imagen monocromática descartada: {file_path}, Saturación: {saturation:.3f}\")\n",
    "            return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error al verificar monocromía: {file_path}, Error: {str(e)}\")\n",
    "        return True\n",
    "\n",
    "def get_phash(file_path):\n",
    "    \"\"\"Calcula el hash perceptual (pHash).\"\"\"\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        return imagehash.phash(img)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def remove_duplicates(file_paths):\n",
    "    \"\"\"Elimina imágenes duplicadas basadas en pHash.\"\"\"\n",
    "    hashes = {}\n",
    "    keep_files = []\n",
    "    for file_path in tqdm(file_paths, desc=\"Buscando duplicados\"):\n",
    "        phash = get_phash(file_path)\n",
    "        if phash is None:\n",
    "            logging.warning(f\"No se pudo calcular pHash: {file_path}\")\n",
    "            continue\n",
    "        duplicate = False\n",
    "        for existing_hash in hashes:\n",
    "            if phash - existing_hash <= PHASH_THRESHOLD:\n",
    "                logging.info(f\"Duplicado encontrado: {file_path}, Similar a: {hashes[existing_hash]}\")\n",
    "                duplicate = True\n",
    "                break\n",
    "        if not duplicate:\n",
    "            hashes[phash] = file_path\n",
    "            keep_files.append(file_path)\n",
    "    return keep_files"
   ],
   "id": "31477f0422a49f93",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:01:24.567514Z",
     "start_time": "2025-04-22T07:01:24.556521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_image(file_path, output_dir, filename):\n",
    "    \"\"\"Procesa una imagen: redimensiona y convierte a JPG.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(file_path).convert('RGB')\n",
    "        img = img.resize(TARGET_SIZE, Image.LANCZOS)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        img.save(output_path, 'JPEG', quality=95)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error al procesar imagen: {file_path}, Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def process_category(category, temp_dir, output_dir, max_images):\n",
    "    \"\"\"Procesa una categoría completa.\"\"\"\n",
    "    category_temp_dir = os.path.join(temp_dir, category.replace(\" \", \"_\"))\n",
    "    category_output_dir = os.path.join(output_dir, category.replace(\" \", \"_\"))\n",
    "    Path(category_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Mostrar rutas\n",
    "    print(f\"\\nProcesando imágenes de '{category}':\")\n",
    "    print(f\" - Origen: {os.path.abspath(category_temp_dir)}\")\n",
    "    print(f\" - Destino: {os.path.abspath(category_output_dir)}\")\n",
    "    logging.info(f\"Procesando '{category}': Origen: {category_temp_dir}, Destino: {category_output_dir}\")\n",
    "    \n",
    "    # Obtener lista de imágenes descargadas\n",
    "    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "    file_paths = [os.path.join(category_temp_dir, f) for f in os.listdir(category_temp_dir) \n",
    "                  if f.lower().endswith(image_extensions)]\n",
    "    \n",
    "    logging.info(f\"Se encontraron {len(file_paths)} imágenes para {category}\")\n",
    "    \n",
    "    # Filtrar imágenes corruptas y de baja resolución\n",
    "    valid_files = []\n",
    "    for file_path in tqdm(file_paths, desc=f\"Filtrando {category} - Corruptas/Baja resolución\"):\n",
    "        if not (is_image_corrupt(file_path) or is_low_resolution(file_path)):\n",
    "            valid_files.append(file_path)\n",
    "    \n",
    "    # Filtrar imágenes monocromáticas\n",
    "    non_monochromatic_files = []\n",
    "    for file_path in tqdm(valid_files, desc=f\"Filtrando {category} - Monocromáticas\"):\n",
    "        if not is_monochromatic(file_path):\n",
    "            non_monochromatic_files.append(file_path)\n",
    "    \n",
    "    # Eliminar duplicados\n",
    "    unique_files = remove_duplicates(non_monochromatic_files)\n",
    "    \n",
    "    # Procesar imágenes (redimensionar y convertir a JPG)\n",
    "    processed_count = 0\n",
    "    for i, file_path in enumerate(tqdm(unique_files, desc=f\"Procesando {category}\")):\n",
    "        if processed_count >= max_images:\n",
    "            break\n",
    "        filename = f\"{category.replace(' ', '_')}_{i+1:04d}.jpg\"\n",
    "        if process_image(file_path, category_output_dir, filename):\n",
    "            processed_count += 1\n",
    "    \n",
    "    logging.info(f\"Procesadas {processed_count} imágenes para {category}\")\n",
    "    return processed_count"
   ],
   "id": "d1364df40c637908",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-22T07:01:31.051515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # Crear directorios\n",
    "    Path(TEMP_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Descargar imágenes para cada categoría\n",
    "    for category in CATEGORIES:\n",
    "        count = download_images(category, TEMP_DIR, IMAGES_PER_CATEGORY)\n",
    "        print(f\"Descargadas {count} imágenes para {category}\")\n",
    "    \n",
    "    # Procesar imágenes para cada categoría\n",
    "    for category in CATEGORIES:\n",
    "        count = process_category(category, TEMP_DIR, OUTPUT_DIR, FINAL_IMAGES_PER_CATEGORY)\n",
    "        print(f\"Procesadas {count} imágenes para {category}\")\n",
    "        \n",
    "    print(f\"Procesamiento completado. Revisa el log en {LOG_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "a2a7097c317b602a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descargando imágenes de 'flowers' en: C:\\Users\\ctorr\\OneDrive\\Documentos\\Arturo\\Arturo HW ITESO\\6to semestre\\Modelos no lineales\\GANs\\data\\raw\\flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Descargando flowers, página 1: 100%|██████████| 100/100 [00:49<00:00,  2.02it/s]\n",
      "Descargando flowers, página 2: 100%|██████████| 100/100 [00:50<00:00,  1.97it/s]\n",
      "Descargando flowers, página 3: 100%|██████████| 100/100 [00:50<00:00,  2.00it/s]\n",
      "Descargando flowers, página 4: 100%|██████████| 100/100 [00:51<00:00,  1.93it/s]\n",
      "Descargando flowers, página 5: 100%|██████████| 100/100 [00:49<00:00,  2.04it/s]\n",
      "Descargando flowers, página 6: 100%|██████████| 100/100 [00:51<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargadas 600 imágenes para flowers\n",
      "\n",
      "Descargando imágenes de 'mountains' en: C:\\Users\\ctorr\\OneDrive\\Documentos\\Arturo\\Arturo HW ITESO\\6to semestre\\Modelos no lineales\\GANs\\data\\raw\\mountains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Descargando mountains, página 1: 100%|██████████| 100/100 [00:51<00:00,  1.94it/s]\n",
      "Descargando mountains, página 2: 100%|██████████| 100/100 [01:12<00:00,  1.38it/s]\n",
      "Descargando mountains, página 3: 100%|██████████| 100/100 [01:13<00:00,  1.37it/s]\n",
      "Descargando mountains, página 4: 100%|██████████| 100/100 [01:13<00:00,  1.36it/s]\n",
      "Descargando mountains, página 5: 100%|██████████| 100/100 [01:13<00:00,  1.37it/s]\n",
      "Descargando mountains, página 6: 100%|██████████| 100/100 [01:13<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargadas 600 imágenes para mountains\n",
      "\n",
      "Descargando imágenes de 'animals' en: C:\\Users\\ctorr\\OneDrive\\Documentos\\Arturo\\Arturo HW ITESO\\6to semestre\\Modelos no lineales\\GANs\\data\\raw\\animals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Descargando animals, página 1: 100%|██████████| 100/100 [01:12<00:00,  1.38it/s]\n",
      "Descargando animals, página 2: 100%|██████████| 100/100 [01:11<00:00,  1.39it/s]\n",
      "Descargando animals, página 3: 100%|██████████| 100/100 [01:13<00:00,  1.37it/s]\n",
      "Descargando animals, página 4:  69%|██████▉   | 69/100 [00:48<00:21,  1.46it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "aa2c53a4e0fcd949",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2a031757c3957133",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d8d4a8f7550a4e91",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
